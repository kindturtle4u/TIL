> 출처 :  자바 알고리즘 인터뷰 with 코틀린: 102가지 알고리즘 문제풀이로 완성하는 코딩테스트(박상길 저)
> 소스코드: https://github.com/onlybooks/java-algorithm-interview

# 05. 빅오
- 빅오(Big-O)는 입력값이 커질 때 알고리즘의 실행 시간(시간 복잡도)과 함께 공간 요구 사항(공간 복잡도)이 어떻게 증가하는지 분류하는데 사용
- 알고리즘의 효율성을 분석하는 데도 매우 유용하게 활용된다.

## 빅오
- `O(1)`: 입력값이 아무리 커도 실행 시간이 일정하다.
- `O(log n)`: 사실상 O(log n) 정도면 최고의 알고리즘이라고 할 수 있다. 대표적으로 이진 검색(Binary Search)이 이에 해당 한다.
- `O(n)`: 정확히 입력값(n)의 크기만큼 실행 시간에 영향을 받으며, 알고리즘을 수행하는데 걸리는 시간은 입력값에 비례한다.
- `O(nlogn)`: 입력값만큼 순회하며 `log n`의 연산이 곱해진다. 병합 정렬을 비롯한 효율적인 정렬 알고리즘이 이에 해당한다.
적어도 모든 수에 대해 한 번 이상을 비교해야 하는 비교 기반 정렬 알고리즘은 아무리 좋은 알고리즘도 `O(n log n)`보다 빠를 수 없다.
좋은 알고리즘이라 칭하는 대부분이 이 범주에 든다. 실용적인 관점에서 `O(n)`이나 `O(n log n)`은 사실상 비슷한 성능으로 가정해도 무방하다.
- `O(n^2)`: 입력값의 제곱만큼 연산한다. 버블 정렬 같은 비효율적인 정렬 알고리즘이 이에 해당한다.
입력값이 클 경우 n^2부터는 타임아웃이 발생하는 경우가 잦기 때문에 코딩 테스트 알고리즘을 최적화 한다고 하면 `O(n^2)`를 `O(n log n)`로 줄이는 일이 거의 대부분이다.
- `O(2^n)`: 입력값의 크기만큼 2배씩 연산한다. 피보나치 수를 재귀로 계산하는 알고리즘 등
2^n은 로그를 반대로 뒤집은 값이라고 보면된다. n^2보다 훨씬 크다. n이 조금만 커져도 사실상 적용하기 어려운 알고리즘.
- `O(n!)`: 각 도시를 방문하고 돌아오는 가장 짧은 경로를 찾은 외판원 문제를 브루트 포스로 풀이할 때 이에 해당한다. `O(n!)`은 가장 느린 알고리즘으로 입력값이 조금만 켜져도
웬만한 다항 시간 내에는 계산이 어렵다.
- `O(1) < O(log n) < O(n) < O(n log n) < O(n^2) < O(2^n) < O(n!)`

### n^2과 2^n의 비교
- n^2에 비해 2^n은 복잡도가 훨씬 더 크므로 서로 혼동하는 일이 없도록 주의해야 하며, O(2^n)인 알고리즘을 설계해서는 안된다.
- 일반적으로 재귀 알고리즘은 실행하는데 O(2^n)의 시간이 걸리는 비효율적인 알고리즘이다. 그러나 메모제이션 같은 최적화를 적용하면 실행 시간을 O(n)까지 줄일 수 있다.

### 빅오를 계산하는 실용적인 방법
```java
public int factorial(int n) {
    if (n >= 1) 
        return n * factorial(n - 1);
    else
        return 1;
}
```
- 얼핏 봐서는 팩토리얼 계산이고 재귀도 있고 하니 시간 복잡도는 O(n!)쯤 될 것 같다. 하지만 자세히 살펴보면 재귀는 n, n-1, n-2 순으로 한번씩만 구하면 되기 때문에 시간 복잡도는
O(n)에 불과하다.
- 다음과 같이 함수를 리턴으로 종료하기 직전에 연산 횟수를 헤아려보자. 이처럼 연산 횟수를 직접 헤아리는 방법이 가장 쉬운 방법이다.
```java
int count = 0;
public int factorial(int n) {
    if (n >= 1) {
        count++;
        return n * factorial(n - 1);
    } else {
        count++;
        return 1;
    }
}
```
### 상한과 최악
- 퀵 정렬의 시간복잡도는 최악의 경우 O(n^2)이며, 최선의 경우 O(n log n)이다.
- 빅오 표기법은 주어신(최선/최악/평균)경우의 수행 시간의 상한을 나타낸다.

### 분할 상환 분석

### 병렬화

### 복잡도의 특징
- 빅오는 시간 복자도 외에도 공간 복잡도를 표현하는 데도 널리 쓰인다.
- 알고리즘은 흔히 '시간과 공간이 트레이드 오프(Space-Time Tradeoff) 관계를 이룬다'고 하는데, 이말은 실행시간 빠른 알고리즘은 공간을 많이 사용하고, 공간을 적게 차지하는 알고리즘은
실행시간이 느리다는 얘기다.

## 자바 컬렉션 프레임워크의 빅오

### 리스트 시간 복잡도

| 연산          | ArrayList    | LinkedList       |
|-------------|--------------|------------------|
| 인덱스 끝에 삽입   | O(1) 가끔 O(n) | O(1)             |
| 인덱스 중간에 삽입  | O(n)         | 탐색 O(n), 삽입 O(1) |
| 인덱스 끝에서 삭제  | O(1)         | O(1)             |
| 인덱스 중간에서 삭제 | O(n)         | 탐색 O(n), 삭재 O(1) |
| 조회          | O(1)         | O(n)             |

### 맵 시간 복잡도

| 연산 | HashMap | LinkedHashMap |
|----|---------|---------------|
| 추가 | O(1)    | O(1)          |
| 삭제 | O(1)    | O(1)          |
| 조회 | O(1)    | O(1)          |

- 아무래도 연결 리스트를 추가로 활용하는 특성상 추가 속도는 LinkedHashMap이 살짝 더 느리다. 그러나 우려할 정도는 아님. 오히려 조회 속도는 LinkedHasMap이 살짝 더 빠르다.
- LinkedHashMap과 HashMap은 사실상 성능이 동일한 자료형으로 봐도 무방하며, 
- 단 LinkedHashMap은 입력 순서가 보장된다는점 그리고 코틀린은 기본적으로 LinkedHashMap을 사용한다는 점.

### 데크 시간 복잡도

| 연산 | ArrayDeque | LinkedList |
|----|------------|------------|
| 삽입 | O(1)       | O(1)       |
| 추출 | O(1)       | O(1)       |

- 데크는 양쪽에서 삽입과 삭제를 할 수 있는, 스택과 큐의 연산을 모두 갖고 있는 독특한 자료형이다.
- 원래 자료형의 성격으로 보자면 이중 연결리스트가 어울리기 때문에 LinkedList가 맞지만, 실제로는 동적 배열로 구현된 ArrayDeque가 좀 더 널리 사용되는 편이다.
- `ArrayDeque`는 자바에서 사실상 스택과 큐를 대체하는 역할을 하는 매우 중요한 자료형. `Stack` 자료형은 성능에 문제가 있어 사용해선 안된다.
- `ArrayDeque<Integer>` 1억개 삽입: 2274ms
- `LinkedList<Integer>` 1억개 삽입: 17228ms
- `ArrayDeque<Integer>` 10만개 추출: 8ms
- `LinkedList<Integer>` 10만개 추출: 6ms
- 삽입 면에서는 속도 차가 많이 나기 때문에 코딩 테스트나 실무에서는 동적 배열로 구현된 `ArrayDeque`를 더 널리 사용한다.
- 동일한 이유로 리스트에서 동적 배열로 구현된 `ArrayList`를 훨씬 더 널리 사용한다.
